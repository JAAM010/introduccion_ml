{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32841519",
   "metadata": {},
   "source": [
    "# 🏡 California Housing Dataset\n",
    "Este notebook demuestra cómo automatizar la descarga de un conjunto de datos desde internet, descomprimirlo y cargarlo en un DataFrame para su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111e1b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38aee4b0",
   "metadata": {},
   "source": [
    "**Contexto:**\n",
    "Los datos que veremos a continuación fueron extraidos del censo de California de 1990. El conjunto de datos contiene información sobre el precio de las viviendas en California, así como características demográficas y socioeconómicas de las áreas. Algunas de las variables son: población, ingresos, número de habitaciones, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cbe8a",
   "metadata": {},
   "source": [
    "## 1. Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75102ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEP8 es una guía de estilo para escribir código Python. (https://www.python.org/dev/peps/pep-0008/)\n",
    "\n",
    "# Librerías estándar de python\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request as request\n",
    "\n",
    "# Librerías de terceros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Librerías locales\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfbc9c",
   "metadata": {},
   "source": [
    "## 2. Definir rutas y URL del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d278d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las constantes son variables que no deberían cambiar su valor a lo largo del programa.\n",
    "# Por convención, se escriben en mayúsculas y con guiones bajos para separar palabras.\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# Creación de constante de forma alternativa:\n",
    "# HOUSING_URL = f\"{DOWNLOAD_ROOT}datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e106231",
   "metadata": {},
   "source": [
    "## 3. Extracción de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e3ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url: str = HOUSING_URL, housing_path: str = HOUSING_PATH) -> None:\n",
    "    # Validamos que el directorio de destino exista, y si no, lo creamos.\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "\n",
    "    # Creamos una variables para almacenar la ruta del archivo comprimido.\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "\n",
    "    # Descargamos el archivo comprimido desde la URL proporcionada y lo guardamos en la ruta especificada.\n",
    "    request.urlretrieve(housing_url, tgz_path)\n",
    "\n",
    "    # Abrimos el archivo comprimido y extraemos su contenido en el directorio especificado.\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "    # Solución alternativa para extraer el contenido del archivo comprimido. Utilizando context manager.\n",
    "    # with tarfile.open(tgz_path, \"r:gz\") as f:\n",
    "    #    f.extractall(path=housing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d307180",
   "metadata": {},
   "source": [
    "### 4.1. Definición de la función `load_housing_data()`\n",
    "Esta función abre el archivo CSV descargado y lo convierte en un DataFrame de pandas para facilitar su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la función para descargar los datos\n",
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13818c89",
   "metadata": {},
   "source": [
    "A continuación, cargamos los datos y mostramos las primeras filas del DataFrame para verificar que la lectura ha sido exitosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6a9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos listar los archivos que se han descargado para verificar que todo está correcto.\n",
    "!ls -l {HOUSING_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b203d",
   "metadata": {},
   "source": [
    "## 4. Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_housing_data(housing_path: str = HOUSING_PATH) -> pd.DataFrame:\n",
    "    # Definimos una variable que almacena la ruta del archivo CSV dentro del directorio de datos.\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    # Leemos el archivo CSV y lo convertimos en un DataFrame de pandas.\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da463f",
   "metadata": {},
   "source": [
    "### 5. Inspección general de los datos\n",
    "Usamos el método `.info()` para conocer el número de columnas, tipos de datos, y si existen valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ff726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a la función para cargar los datos en un DataFrame de pandas.\n",
    "# El resultado de la función lo almacenamos en una variable llamada `housing`.\n",
    "housing = load_housing_data()\n",
    "\n",
    "# Presentamos las primeras 5 filas del DataFrame para verificar que los datos se han cargado correctamente.\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770d146",
   "metadata": {},
   "source": [
    "## 5. EDA: Exploración de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c73e14",
   "metadata": {},
   "source": [
    "### 5.1 Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e5051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El método `info()` nos proporciona un resumen del DataFrame, incluyendo el número de entradas, tipos de datos y valores no nulos.\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35241269",
   "metadata": {},
   "source": [
    "Usamos `.describe()` para obtener estadísticas descriptivas como media, desviación estándar, mínimo y máximo por columna numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"ocean_proximity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566ebde6",
   "metadata": {},
   "source": [
    "### 5.2 Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El método `describe()` nos proporciona estadísticas descriptivas de las columnas numéricas del DataFrame.\n",
    "housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49829bc1",
   "metadata": {},
   "source": [
    "### 5.3 Histograma de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bd794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El método `hist()` nos permite visualizar la distribución de los datos numéricos en el DataFrame.\n",
    "housing.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282432f",
   "metadata": {},
   "source": [
    "### 5.1. Visualización inicial\n",
    "Graficamos histogramas de las variables numéricas para ver su distribución y detectar posibles valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bc358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de las columnas del DataFrame `housing`.\n",
    "housing.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99dbdc",
   "metadata": {},
   "source": [
    "## 🧪 6. Preparación de los datos\n",
    "En esta sección prepararemos los datos para un futuro modelo de machine learning. Esto incluye manejo de valores faltantes, codificación de variables categóricas, y separación de variables predictoras y objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde01cf",
   "metadata": {},
   "source": [
    "### 6.1 Dividir el conjunto de datos entre Train y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee60df",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train, housing_test = train_test_split(housing, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87743710",
   "metadata": {},
   "source": [
    "### 6.1. Identificación de valores faltantes\n",
    "Contamos los valores nulos por columna para saber dónde debemos aplicar imputación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb22aa3",
   "metadata": {},
   "source": [
    "Aquí observamos que `total_bedrooms` tiene valores faltantes. Vamos a imputarlos con la mediana, una estrategia común."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5facaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8b7d0b",
   "metadata": {},
   "source": [
    "Obtenemos la mediana de la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f17591",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ed1e",
   "metadata": {},
   "source": [
    "Rellenamos los valores nulos de `total_bedrooms` usando esa mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e04d66a",
   "metadata": {},
   "source": [
    "Verificamos que ya no hay valores nulos en `total_bedrooms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e462908",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00331c",
   "metadata": {},
   "source": [
    "Confirmamos que el DataFrame ya no contiene valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0100ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.loc[:, housing.columns != \"ocean_proximity\"].corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b1fc7",
   "metadata": {},
   "source": [
    "### 6.2. Codificación de variables categóricas\n",
    "Convertimos la columna `ocean_proximity` en variables numéricas utilizando codificación one-hot con `pd.get_dummies()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13127600",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246819df",
   "metadata": {},
   "source": [
    "### 6.2 Ingeniería de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8900af",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5cfac",
   "metadata": {},
   "source": [
    "### 6.3. Separación de variables predictoras y objetivo\n",
    "Separaremos nuestro dataset en `X` (las columnas que usaremos para predecir) y `y` (la variable que queremos predecir: `median_house_value`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b73efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.loc[:, housing.columns != \"ocean_proximity\"].corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04298d22",
   "metadata": {},
   "source": [
    "### 6.3 Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707fbe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = housing_train.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = housing_train[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f996b4a4",
   "metadata": {},
   "source": [
    "#### 6.3.1. Manejo de valores faltantes\n",
    "Primero identificamos columnas con valores faltantes. Luego decidiremos si los eliminamos o los imputamos (rellenamos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6db53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cuántos valores faltantes hay en cada columna\n",
    "housing.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b485298d",
   "metadata": {},
   "source": [
    "### 6.4. Escalado de variables numéricas\n",
    "Escalamos las columnas numéricas con `StandardScaler` para que todas tengan media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04c8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[housing[\"total_bedrooms\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a3523",
   "metadata": {},
   "source": [
    "Vemos que la columna `total_bedrooms` contiene valores faltantes. Vamos a reemplazarlos con la **mediana** de esa columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a obtener la mediana de la columna \"total_bedrooms\" para rellenar los valores faltantes.\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8186492",
   "metadata": {},
   "source": [
    "Aplicamos el escalado sobre los datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad32283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que la imputación de datos solo se puede aplicar a columnas numéricas, vamos a crear un nuevo DataFrame que contenga solo las columnas numéricas.\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2029c",
   "metadata": {},
   "source": [
    "Convertimos la salida escalada a un DataFrame de pandas con nombres de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "imputer.fit(housing_num)\n",
    "\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84487f4",
   "metadata": {},
   "source": [
    "Identificamos las columnas categóricas que ya han sido codificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c150bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\n",
    "housing_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df68aecb",
   "metadata": {},
   "source": [
    "Unimos las columnas numéricas escaladas con las categóricas codificadas para formar `X_preparado`, listo para entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77668c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validamos que ya no hay valores faltantes en la columna \"total_bedrooms\".\n",
    "assert not housing_tr[\"total_bedrooms\"].isnull().any(), \"Hay valores faltantes en total_bedrooms\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61179eb",
   "metadata": {},
   "source": [
    "Mostramos las primeras filas del dataset final preparado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d513e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la información del DataFrame para verificar que los cambios se han aplicado correctamente.\n",
    "housing_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212fd3a9",
   "metadata": {},
   "source": [
    "#### 6.3.2. Codificación de variables categóricas\n",
    "La columna `ocean_proximity` es de tipo texto (categórica). Vamos a convertirla en variables numéricas usando codificación *one-hot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d2639",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe6bb6",
   "metadata": {},
   "source": [
    "### 6.5. Selección de variables con OLS (Ordinary Least Squares)\n",
    "Ajustamos un modelo de regresión lineal para ver qué variables son más significativas al predecir el valor de la vivienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae57078",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670af2b0",
   "metadata": {},
   "source": [
    "Usamos `statsmodels` para entrenar el modelo con todas las variables, incluyendo una constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a78afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce43852",
   "metadata": {},
   "source": [
    "Mostramos el resumen del modelo OLS con coeficientes, errores estándar, R² y p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea226edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot.toarray()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d48725",
   "metadata": {},
   "source": [
    "### 6.6. Filtrar variables significativas\n",
    "Seleccionamos las variables cuyo p-value sea menor a 0.05 para construir un subconjunto más relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ca9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot = pd.DataFrame(housing_cat_1hot.toarray(), columns=cat_encoder.get_feature_names_out(), index=housing_cat.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfd6d8d",
   "metadata": {},
   "source": [
    "#### 6.3.3. Escalar las variables numéricas\n",
    "\n",
    "El escalado es importante para que todas las variables numéricas tengan un rango comparable, especialmente si vamos a usar modelos sensibles a magnitudes como regresión lineal o redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ceb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "housing_num_tr = scaler.fit_transform(housing_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488dc35",
   "metadata": {},
   "source": [
    "Extraemos los nombres de variables con significancia estadística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(housing_num_tr, columns=housing_tr.columns, index=housing_tr.index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6af59",
   "metadata": {},
   "source": [
    "Creamos un nuevo DataFrame `X_filtrado` con solo esas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr = pd.DataFrame(housing_num_tr, columns=housing_tr.columns, index=housing_tr.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea47cdd",
   "metadata": {},
   "source": [
    "Mostramos las primeras filas del nuevo dataset filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467384f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinamos numéricas escaladas + categóricas codificadas\n",
    "housing_prepared = pd.concat([housing_num_tr, housing_cat_1hot], axis=1)\n",
    "housing_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2128c66",
   "metadata": {},
   "source": [
    "### 6.4 Uso de `Pipeline` de Scikit-learn\n",
    "\n",
    "Usaremos un `Pipeline` para encadenar los pasos de preprocesamiento y entrenamiento del modelo. Esto nos permite aplicar transformaciones de manera ordenada y reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32476265",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244fffe",
   "metadata": {},
   "source": [
    "Ahora nuestro dataset está limpio, escalado, codificado y filtrado con variables relevantes listas para modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs), (\"cat\", OneHotEncoder(), cat_attribs)])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf355ae",
   "metadata": {},
   "source": [
    "### 7. Selección y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eefe39",
   "metadata": {},
   "source": [
    "Verificamos la forma final de `X_filtrado`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e31871",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_in = housing.iloc[:5]\n",
    "datos_out = housing_labels.iloc[:5]\n",
    "\n",
    "datos_preparados = full_pipeline.transform(datos_in)\n",
    "predicciones = lin_reg.predict(datos_preparados)\n",
    "\n",
    "print(\"Predicciones:\", predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75bf7ac",
   "metadata": {},
   "source": [
    "Confirmamos que `y` sigue alineado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reales:\", list(datos_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbdc9bc",
   "metadata": {},
   "source": [
    "### 8. Evaluación del modelo\n",
    "\n",
    "En esta sección evaluaremos el rendimiento del modelo utilizando métricas como RMSE (Raíz del Error Cuadrático Medio) y R² (Coeficiente de Determinación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lin_reg.predict(housing_prepared)\n",
    "mse = mean_squared_error(housing_labels, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff1127",
   "metadata": {},
   "source": [
    "🎉 ¡Listo! Hemos preparado un dataset completamente procesado para entrenar modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93390c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(housing_labels, predictions)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cce8e1",
   "metadata": {},
   "source": [
    "Entendiendo las métricas:\n",
    "- **RMSE**: Mide el error promedio entre las predicciones del modelo y los valores reales.\n",
    "    - Se calcula como la raíz cuadrada del error cuadrático medio (MSE).\n",
    "    - Interpretación: valores más bajos indican mejor desempeño.\n",
    "    - Está en la misma unidad que la variable objetivo (median_house_value en este caso).\n",
    "- **R²**: Indica qué porcentaje de la variabilidad en los datos es explicado por el modelo.\n",
    "    - Su valor va de 0 a 1 (en algunos casos puede ser negativo).\n",
    "    - Un valor de 0.85 significa que el modelo explica el 85% de la variabilidad de los datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
